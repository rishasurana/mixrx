{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    text = f\"### Prompt: {example['input']}\\n  ### Context: {example['input']}\\n  ### Prediction: {example['input']}\\n  ### Reasoning: {example['output']}\"\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyBggVlYj0gY",
        "outputId": "75304c77-6b60-4fea-e1cd-cc0b560e9bea"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "Can't load tokenizer for 'mistralai/Mistral-7B-Instruct-v0.2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'mistralai/Mistral-7B-Instruct-v0.2' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# the device to load the model onto\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2074\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2068\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2070\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2071\u001b[0m     )\n\u001b[1;32m   2073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2074\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2075\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2079\u001b[0m     )\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'mistralai/Mistral-7B-Instruct-v0.2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'mistralai/Mistral-7B-Instruct-v0.2' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer."
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "text = \"Replace me by any text you'd like.\", \"Hello\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt', padding=True, padding_side='left')\n",
        "\n",
        "# output = model(**encoded_input)\n",
        "\n",
        "input_ids = encoded_input['input_ids']\n",
        "\n",
        "# Generate text response\n",
        "max_length = 50  # Maximum length of the generated response\n",
        "temperature = 0.7  # Temperature parameter for sampling\n",
        "top_k = 50  # Top-k sampling parameter\n",
        "top_p = 0.9  # Top-p sampling parameter\n",
        "\n",
        "# Generate text using the model\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    temperature=temperature,\n",
        "    top_k=top_k,\n",
        "    top_p=top_p,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "# Decode the generated token IDs into text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Generated text:\", generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzOij-wQM36b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, load_from_disk, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "d1eaaccdde3d4ae98267a02a10eb5745",
            "b4f061e8a2ad4172bafeef9137675f3a",
            "a4bda9c9b4184272b4c223c315d2544d",
            "f66a230d623e4a1891260e879c438ccc",
            "09f18051fe6d4f0184d144714e4fc17f",
            "99e637152d8f4901a333dd53f89a1130",
            "cedf5959a3e44921916e4240ad13364b",
            "adf2d4c02cf44003b3d2167d48d9e39f",
            "bc2a977afe534d55b760950b1a2a5fe6",
            "92a29b7e24e84e94a98e6ac1687100b5",
            "ecb1cc1635904d0780e3929e076f2479"
          ]
        },
        "id": "UgyyP_T0DhIi",
        "outputId": "cbfed3b9-90cc-424e-83d0-3fbaac3bad2b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1eaaccdde3d4ae98267a02a10eb5745",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 10000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Create prompt tensors from prompts_contexts.csv file.\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "prompts_contexts = '../preprocessing/updated_prompts_contexts.csv'\n",
        "# prompts_contexts = '/content/drive/MyDrive/CSCI499 Natural Language Processing/preprocessing/updated_prompts_contexts.csv'\n",
        "df = pd.read_csv(prompts_contexts)\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "def create_mult_seq(example):\n",
        "    sentences = []\n",
        "    # Concatenate sentences from all fields\n",
        "    for column, value in example.items():\n",
        "        sentences.extend(value.split('.'))  # Split sentences based on '. ' delimiter\n",
        "\n",
        "    example['Sequences'] = sentences\n",
        "    tokens = tokenizer(example['Sequences'])\n",
        "    examples['input_ids'] = tokens['input_ids']\n",
        "    # examples['mask???'] = tokens['mask???']\n",
        "    return example\n",
        "\n",
        "def tokenize(example):\n",
        "  example = tokenizer(example['Prompt'], example['Context'], example['Updated Context'], truncation=True, padding=True, return_tensors=\"pt\")\n",
        "  return example\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['Prompt', 'Context', 'Updated Context', 'labels'])\n",
        "print(tokenized_dataset)\n",
        "\n",
        "# Split the dataset into train/test/valid (80/10/10)\n",
        "train_test_ds = tokenized_dataset.train_test_split(test_size=.2)\n",
        "test_valid_ds = train_test_ds['test'].train_test_split(test_size=.5)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    'train': train_test_ds['train'],\n",
        "    'test': test_valid_ds['test'],\n",
        "    'valid': test_valid_ds['train']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WeABULaTNPL",
        "outputId": "748cb90c-8b2e-41b4-acfc-4e43665ecec8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Gemcitabine, PictilisibPictilisib and Gemcitabine have a Loewe score of: -0.1477, HSA score of: -0.5063, and ZIP score of: -0.6687.The results of this study indicate that the synergistic effect of the drug combination is achieved only when the combination of Gemcitabine, Pictilisib and Pictilisib is combined with a drug that has a Loewe score of: -0.1477, HSA score of: -0.5063, and ZIP score of: -0\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Trametinib, Alvespimycin, Dasatinib, Pemetrexed, GSK2334470Alvespimycin and GSK2334470 have a Loewe score of: -0.3629, HSA score of: -0.3789, and ZIP score of: -0.7793. GSK2334470 and Pemetrexed have a Loewe score of: -0.1537, HSA score of: -0.2081, and ZIP score of: -0.8464. Dasatinib and GSK2334470 have a Loewe score of: -0.379, HSA score of: -0.3944, and ZIP score of: -0.8608. Trametinib and GSK2334470 have a Loewe score of: -0.4428, HSA score of: -0.4357, and ZIP score of: -0.9044. Alvespimycin and Pemetrexed have a Loewe score of: -0.1934, HSA score of: -0.2221, and ZIP score of: -0.7704. Alvespimycin and Dasatinib have a Loewe score of: -0.0415, HSA score of: -0.1641, and ZIP score of: -0.76. Alvespimycin and Trametinib have a Loewe score of: -0.187, HSA score of: -0.2313, and ZIP score of: -0.7286. Dasatinib and Pemetrexed have a Loewe score of: -0.1428, HSA score of: -0.2247, and ZIP score of: -0.8374. Trametinib and Pemetrexed have a Loewe score of: -0.2832, HSA score of: -0.37, and ZIP score of: -0.7706. Dasatinib and Trametinib have a Loewe score of: -0.2339, HSA score of: -0.3408, and ZIP score of: -0.8124.The effect size of the drug combination is as follows: -0.11. The dose range for the combination is as follows: -0.2. The dose range for the combination is as follows: -0.24. The dose range for the combination is as follows: -0.32. The dose range for the combination is as follows: -0.\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Zocor, CREBi1, Thapsigargin, VenetoclaxCREBi1 and Thapsigargin have a Loewe score of: -0.0798, HSA score of: -0.0798, and ZIP score of: -0.99. Venetoclax and CREBi1 have a Loewe score of: -0.0095, HSA score of: -0.0095, and ZIP score of: -0.9722. CREBi1 and Zocor have a Loewe score of: -0.2099, HSA score of: -0.2093, and ZIP score of: -0.9865. Venetoclax and Thapsigargin have a Loewe score of: -0.0433, HSA score of: -0.0433, and ZIP score of: -0.9855. Zocor and Thapsigargin have a Loewe score of: -0.426, HSA score of: -0.4258, and ZIP score of: -0.9865. Venetoclax and Zocor have a Loewe score of: -0.0424, HSA score of: -0.042, and ZIP score of: -0.9829.\"\n",
            "\n",
            "\"It is not clear why, if the drug combination has a higher HSA score than the drug combination alone, it is not a synergistic drug. It is a low-dose combination of two drugs and the drug combination does not have a synergistic effect on the liver. The combination of two drugs is a low-dose combination and the drug combination\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Sepantronium Bromide, Afatinib, Paclitaxel, Dasatinib, CrizotinibPaclitaxel and Sepantronium Bromide have a Loewe score of: -0.4056, HSA score of: -0.5767, and ZIP score of: -0.7755. Crizotinib and Paclitaxel have a Loewe score of: -0.5166, HSA score of: -0.5219, and ZIP score of: -0.8881. Dasatinib and Paclitaxel have a Loewe score of: -0.2062, HSA score of: -0.2998, and ZIP score of: -0.8143. Afatinib and Paclitaxel have a Loewe score of: -0.3952, HSA score of: -0.4096, and ZIP score of: -0.8605. Crizotinib and Sepantronium Bromide have a Loewe score of: -0.1982, HSA score of: -0.1982, and ZIP score of: -0.881. Dasatinib and Sepantronium Bromide have a Loewe score of: -0.3524, HSA score of: -0.4862, and ZIP score of: -0.7148. Afatinib and Sepantronium Bromide have a Loewe score of: -0.3327, HSA score of: -0.3665, and ZIP score of: -0.8363. Crizotinib and Dasatinib have a Loewe score of: -0.4206, HSA score of: -0.4798, and ZIP score of: -0.8522. Afatinib and Crizotinib have a Loewe score of: -0.2536, HSA score of: -0.2615, and ZIP score of: -0.9603. Afatinib and Dasatinib have a Loewe score of: -0.1475, HSA score of: -0.1181, and ZIP score of: -0.8891.A third set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Sepantronium Bromide, AgonistinibPaclitaxel, Glucopyride, Adopamine, Dopamine, and Amorphin have a Loewe score of: -0.5541, HSA score of\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: SB-225002, GSK2334470, Alisertib, PictilisibGSK2334470 and SB-225002 have a Loewe score of: -0.6048, HSA score of: -0.602, and ZIP score of: -0.8277. GSK2334470 and Alisertib have a Loewe score of: -0.3067, HSA score of: -0.3968, and ZIP score of: -0.8502. Pictilisib and GSK2334470 have a Loewe score of: -0.4657, HSA score of: -0.4583, and ZIP score of: -0.9069. Alisertib and SB-225002 have a Loewe score of: -0.3145, HSA score of: -0.4126, and ZIP score of: -0.8399. Pictilisib and SB-225002 have a Loewe score of: -0.3227, HSA score of: -0.4443, and ZIP score of: -0.8095. Pictilisib and Alisertib have a Loewe score of: -0.2094, HSA score of: -0.3722, and ZIP score of: -0.8025.The total of the three drugs is: SB-225002, GSK2334470, Alisertib, PictilisibGSK2334470 and SB-225002 have a Loewe score of: 0.5527, HSA score of: 0.4273, and ZIP score of: -0.8177. GSK\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Oligomycins, VenetoclaxVenetoclax and Oligomycins have a Loewe score of: -0.2503, HSA score of: -0.2503, and ZIP score of: -0.9434.I have shown that the Oligomycins are synergistic, and that Oligomycins have a Loewe score of: -0.24, HSA score of: -0.24, and ZIP score of: -0.9174.\n",
            "\n",
            "We can use the following equation to calculate the synergistic effect of the drug combination:\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Sepantronium Bromide, AZD-7762, Oligomycins, SN 38 LactoneOligomycins and SN 38 Lactone have a Loewe score of: -0.285, HSA score of: -0.2864, and ZIP score of: -0.7615. AZD-7762 and SN 38 Lactone have a Loewe score of: -0.2088, HSA score of: -0.21, and ZIP score of: -0.6888. SN 38 Lactone and Sepantronium Bromide have a Loewe score of: -0.3381, HSA score of: -0.5607, and ZIP score of: -0.6161. AZD-7762 and Oligomycins have a Loewe score of: -0.5381, HSA score of: -0.5435, and ZIP score of: -0.7407. Oligomycins and Sepantronium Bromide have a Loewe score of: -0.4812, HSA score of: -0.5122, and ZIP score of: -0.8381. AZD-7762 and Sepantronium Bromide have a Loewe score of: 0.066, HSA score of: -0.44, and ZIP score of:.If the synergy of the drug combination is synergistic or antagonistic: Sepantronium Bromide, AZD-7762, Oligomycins, SN 38 LactoneOligomycins and SN 38 Lactone have a Loewe score of: 0.066, HSA score of: -0.44, and ZIP\n",
            "Generated text: Given the following set of drugs, decide if the synergy of the drug combination is synergistic or antagonistic: Crizotinib, Oligomycins, PF-431396Oligomycins and PF-431396 have a Loewe score of: -0.4986, HSA score of: -0.5439, and ZIP score of: -0.8384. Oligomycins and PF-431396 have a Loewe score of: -0.4986, HSA score of: -0.5439, and ZIP score of: -0.8384. Crizotinib and PF-431396 have a Loewe score of: -0.502, HSA score of: -0.502, and ZIP score of: -0.8852. Oligomycins and Oligomycins have a Loewe score of: -0.3748, HSA score of: -0.376, and ZIP score of: -0.9026. Crizotinib and Oligomycins have a Loewe score of: -0.4297, HSA score of: -0.4297, and ZIP score of: -0.9434. Crizotinib and Oligomycins have a Loewe score of: -0.4297, HSA score of: -0.4297, and ZIP score of: -0.9434.The combination of the drugs is considered synergistic by the researchers, while the drug combination is considered antagonistic by the researchers. The researchers conclude that the combination of the drugs is effective against the development of diabetes and is thus a promising treatment option for patients with diabetes. The combination of the drugs is considered synergistic by the researchers, while the drug combination is considered antagonistic\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    ds[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    ds[\"valid\"], batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "# Generate text response\n",
        "max_length = 600  # Maximum length of the generated response\n",
        "temperature = 0.7  # Temperature parameter for sampling\n",
        "top_k = 50  # Top-k sampling parameter\n",
        "top_p = 0.9  # Top-p sampling parameter\n",
        "\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v for k, v in batch.items()}\n",
        "\n",
        "        # Generate text using the model\n",
        "        output = model.generate(\n",
        "            # input_ids,\n",
        "            **batch,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "\n",
        "        # Decode the generated token IDs into text\n",
        "        generated_text = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
        "\n",
        "        [print(\"Generated text:\", text) for text in generated_text]\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09f18051fe6d4f0184d144714e4fc17f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a29b7e24e84e94a98e6ac1687100b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e637152d8f4901a333dd53f89a1130": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4bda9c9b4184272b4c223c315d2544d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf2d4c02cf44003b3d2167d48d9e39f",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc2a977afe534d55b760950b1a2a5fe6",
            "value": 10000
          }
        },
        "adf2d4c02cf44003b3d2167d48d9e39f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f061e8a2ad4172bafeef9137675f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e637152d8f4901a333dd53f89a1130",
            "placeholder": "​",
            "style": "IPY_MODEL_cedf5959a3e44921916e4240ad13364b",
            "value": "Map: 100%"
          }
        },
        "bc2a977afe534d55b760950b1a2a5fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cedf5959a3e44921916e4240ad13364b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1eaaccdde3d4ae98267a02a10eb5745": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4f061e8a2ad4172bafeef9137675f3a",
              "IPY_MODEL_a4bda9c9b4184272b4c223c315d2544d",
              "IPY_MODEL_f66a230d623e4a1891260e879c438ccc"
            ],
            "layout": "IPY_MODEL_09f18051fe6d4f0184d144714e4fc17f"
          }
        },
        "ecb1cc1635904d0780e3929e076f2479": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f66a230d623e4a1891260e879c438ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a29b7e24e84e94a98e6ac1687100b5",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb1cc1635904d0780e3929e076f2479",
            "value": " 10000/10000 [01:00&lt;00:00, 226.82 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
